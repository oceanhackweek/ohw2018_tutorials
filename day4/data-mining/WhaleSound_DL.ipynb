{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to run a simple deep learning model to classify whale calls. We use the [keras](https://keras.io/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing multiple visualization libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import pylab as pl\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries to manipulate the data files\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a library to read the .aiff format\n",
    "import aifc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(os.path.join('whale_data','train','*.aiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentina/anaconda/envs/data_mining_test/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# read signals and apply the welch filter\n",
    "feature_dict = {}\n",
    "fs = 2000\n",
    "for filename in filenames[::1]:\n",
    "    aiff = aifc.open(filename,'r')\n",
    "    whale_strSig = aiff.readframes(aiff.getnframes())\n",
    "    whale_array = np.fromstring(whale_strSig, np.short).byteswap()\n",
    "    feature = 10*np.log10(signal.welch(whale_array, fs=fs, window='hanning', nperseg=256, noverlap=128+64)[1])\n",
    "    feature_dict[filename] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 30000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "XX = pd.DataFrame(feature_dict)\n",
    "XX = np.array(XX)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning on time domain samples.\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 129)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_names = ['Upcall', 'NO_Upcall']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX.T, y, test_size=0.20, random_state=2018)\n",
    "\n",
    "# Convert label to onehot\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 3, activation='relu', input_shape=(129, 1)))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'deep_1'\n",
    "top_weights_path = 'model_' + str(model_name) + '.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(top_weights_path, monitor = 'val_acc', verbose = 1, save_best_only = True, save_weights_only = True), \n",
    "    EarlyStopping(monitor = 'val_acc', patience = 6, verbose = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, patience = 3, verbose = 1),\n",
    "    CSVLogger('model_' + str(model_name) + '.log')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of jargon:\n",
    "\n",
    "\n",
    "* Max Pooling/ Average Pooling\n",
    "* Batch normalization\n",
    "* Epochs\n",
    "* Adam Optimizer\n",
    "* Convolutional Layers\n",
    "* Cross Entropy\n",
    "* Adam Optimizer\n",
    "* ReLU\n",
    "* Batch Size\n",
    "* Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "#plot_model(model,to_file='model_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![new text](model_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fitting the Model (this will take a loooooooot of time)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data = [X_test, y_test], callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with tensorboard to monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "24000/24000 [==============================] - 19s 796us/step - loss: 0.4787 - acc: 0.7856 - val_loss: 0.4562 - val_acc: 0.8132\n",
      "Epoch 2/100\n",
      "24000/24000 [==============================] - 19s 801us/step - loss: 0.3990 - acc: 0.8258 - val_loss: 0.4488 - val_acc: 0.7990\n",
      "Epoch 3/100\n",
      "24000/24000 [==============================] - 22s 914us/step - loss: 0.3690 - acc: 0.8387 - val_loss: 0.3740 - val_acc: 0.8297\n",
      "Epoch 4/100\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: 0.3457 - acc: 0.8475 - val_loss: 0.3489 - val_acc: 0.8395\n",
      "Epoch 5/100\n",
      "24000/24000 [==============================] - 21s 894us/step - loss: 0.3332 - acc: 0.8521 - val_loss: 0.3475 - val_acc: 0.8397\n",
      "Epoch 6/100\n",
      "24000/24000 [==============================] - 22s 898us/step - loss: 0.3213 - acc: 0.8589 - val_loss: 0.3496 - val_acc: 0.8468\n",
      "Epoch 7/100\n",
      "24000/24000 [==============================] - 21s 891us/step - loss: 0.3124 - acc: 0.8630 - val_loss: 0.3205 - val_acc: 0.8523\n",
      "Epoch 8/100\n",
      "24000/24000 [==============================] - 22s 910us/step - loss: 0.3050 - acc: 0.8652 - val_loss: 0.3124 - val_acc: 0.8585\n",
      "Epoch 9/100\n",
      "24000/24000 [==============================] - 21s 865us/step - loss: 0.2972 - acc: 0.8684 - val_loss: 0.3104 - val_acc: 0.8622\n",
      "Epoch 10/100\n",
      "24000/24000 [==============================] - 23s 950us/step - loss: 0.2954 - acc: 0.8714 - val_loss: 0.3029 - val_acc: 0.8635\n",
      "Epoch 11/100\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.2873 - acc: 0.8734 - val_loss: 0.3384 - val_acc: 0.8460\n",
      "Epoch 12/100\n",
      "24000/24000 [==============================] - 30s 1ms/step - loss: 0.2849 - acc: 0.8762 - val_loss: 0.5660 - val_acc: 0.7790\n",
      "Epoch 13/100\n",
      "24000/24000 [==============================] - 35s 1ms/step - loss: 0.2807 - acc: 0.8752 - val_loss: 0.3031 - val_acc: 0.8660\n",
      "Epoch 14/100\n",
      "24000/24000 [==============================] - 40s 2ms/step - loss: 0.2763 - acc: 0.8790 - val_loss: 0.3066 - val_acc: 0.8622\n",
      "Epoch 15/100\n",
      "24000/24000 [==============================] - 35s 1ms/step - loss: 0.2734 - acc: 0.8803 - val_loss: 0.2995 - val_acc: 0.8655\n",
      "Epoch 16/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.2690 - acc: 0.8817 - val_loss: 0.3019 - val_acc: 0.8628\n",
      "Epoch 17/100\n",
      "24000/24000 [==============================] - 29s 1ms/step - loss: 0.2650 - acc: 0.8858 - val_loss: 0.3050 - val_acc: 0.8667\n",
      "Epoch 18/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.2632 - acc: 0.8838 - val_loss: 0.3418 - val_acc: 0.8432\n",
      "Epoch 19/100\n",
      "24000/24000 [==============================] - 34s 1ms/step - loss: 0.2572 - acc: 0.8886 - val_loss: 0.3043 - val_acc: 0.8628\n",
      "Epoch 20/100\n",
      "24000/24000 [==============================] - 29s 1ms/step - loss: 0.2538 - acc: 0.8914 - val_loss: 0.3012 - val_acc: 0.8692\n",
      "Epoch 21/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.2495 - acc: 0.8911 - val_loss: 0.3345 - val_acc: 0.8443\n",
      "Epoch 22/100\n",
      "24000/24000 [==============================] - 36s 2ms/step - loss: 0.2479 - acc: 0.8930 - val_loss: 0.3029 - val_acc: 0.8655\n",
      "Epoch 23/100\n",
      "24000/24000 [==============================] - 37s 2ms/step - loss: 0.2448 - acc: 0.8938 - val_loss: 0.3140 - val_acc: 0.8557\n",
      "Epoch 24/100\n",
      "24000/24000 [==============================] - 40s 2ms/step - loss: 0.2434 - acc: 0.8946 - val_loss: 0.3260 - val_acc: 0.8547\n",
      "Epoch 25/100\n",
      "24000/24000 [==============================] - 37s 2ms/step - loss: 0.2370 - acc: 0.8976 - val_loss: 0.3153 - val_acc: 0.8627\n",
      "Epoch 26/100\n",
      "24000/24000 [==============================] - 30s 1ms/step - loss: 0.2364 - acc: 0.8967 - val_loss: 0.3095 - val_acc: 0.8667\n",
      "Epoch 27/100\n",
      "24000/24000 [==============================] - 21s 886us/step - loss: 0.2285 - acc: 0.9024 - val_loss: 0.5254 - val_acc: 0.8010\n",
      "Epoch 28/100\n",
      "24000/24000 [==============================] - 21s 888us/step - loss: 0.2271 - acc: 0.9046 - val_loss: 0.3151 - val_acc: 0.8640\n",
      "Epoch 29/100\n",
      "24000/24000 [==============================] - 22s 922us/step - loss: 0.2205 - acc: 0.9059 - val_loss: 0.3150 - val_acc: 0.8578\n",
      "Epoch 30/100\n",
      "24000/24000 [==============================] - 23s 947us/step - loss: 0.2173 - acc: 0.9077 - val_loss: 0.3516 - val_acc: 0.8415\n",
      "Epoch 31/100\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: 0.2141 - acc: 0.9092 - val_loss: 0.3369 - val_acc: 0.8555\n",
      "Epoch 32/100\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 0.2068 - acc: 0.9135 - val_loss: 0.3314 - val_acc: 0.8615\n",
      "Epoch 33/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.2076 - acc: 0.9142 - val_loss: 0.3438 - val_acc: 0.8565\n",
      "Epoch 34/100\n",
      "24000/24000 [==============================] - 46s 2ms/step - loss: 0.1981 - acc: 0.9191 - val_loss: 0.3703 - val_acc: 0.8435\n",
      "Epoch 35/100\n",
      "24000/24000 [==============================] - 37s 2ms/step - loss: 0.1968 - acc: 0.9183 - val_loss: 0.3539 - val_acc: 0.8448\n",
      "Epoch 36/100\n",
      "24000/24000 [==============================] - 35s 1ms/step - loss: 0.1958 - acc: 0.9198 - val_loss: 0.3338 - val_acc: 0.8613\n",
      "Epoch 37/100\n",
      "24000/24000 [==============================] - 34s 1ms/step - loss: 0.1906 - acc: 0.9206 - val_loss: 0.5295 - val_acc: 0.8152\n",
      "Epoch 38/100\n",
      "24000/24000 [==============================] - 34s 1ms/step - loss: 0.1853 - acc: 0.9242 - val_loss: 0.3293 - val_acc: 0.8660\n",
      "Epoch 39/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.1808 - acc: 0.9251 - val_loss: 0.4504 - val_acc: 0.8475\n",
      "Epoch 40/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.1749 - acc: 0.9290 - val_loss: 0.3759 - val_acc: 0.8555\n",
      "Epoch 41/100\n",
      "24000/24000 [==============================] - 31s 1ms/step - loss: 0.1744 - acc: 0.9295 - val_loss: 0.3828 - val_acc: 0.8540\n",
      "Epoch 42/100\n",
      "24000/24000 [==============================] - 32s 1ms/step - loss: 0.1698 - acc: 0.9304 - val_loss: 0.4209 - val_acc: 0.8378\n",
      "Epoch 43/100\n",
      "24000/24000 [==============================] - 34s 1ms/step - loss: 0.1686 - acc: 0.9334 - val_loss: 0.3705 - val_acc: 0.8573\n",
      "Epoch 44/100\n",
      "24000/24000 [==============================] - 35s 1ms/step - loss: 0.1639 - acc: 0.9321 - val_loss: 0.3907 - val_acc: 0.8530\n",
      "Epoch 45/100\n",
      "24000/24000 [==============================] - 35s 1ms/step - loss: 0.1561 - acc: 0.9370 - val_loss: 0.4282 - val_acc: 0.8373\n",
      "Epoch 46/100\n",
      "24000/24000 [==============================] - 38s 2ms/step - loss: 0.1516 - acc: 0.9398 - val_loss: 0.5914 - val_acc: 0.8217\n",
      "Epoch 47/100\n",
      "24000/24000 [==============================] - 38s 2ms/step - loss: 0.1513 - acc: 0.9401 - val_loss: 0.3898 - val_acc: 0.8567\n",
      "Epoch 48/100\n",
      "24000/24000 [==============================] - 41s 2ms/step - loss: 0.1424 - acc: 0.9430 - val_loss: 0.3737 - val_acc: 0.8582\n",
      "Epoch 49/100\n",
      " 4096/24000 [====>.........................] - ETA: 32s - loss: 0.1355 - acc: 0.9487"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data = [X_test, y_test], callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred[y_test == 1]>.1)/len(y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test.astype('int'), y_pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test.astype('int'), y_pred)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[Deep Learning Glossary](http://www.wildml.com/deep-learning-glossary/)\n",
    "\n",
    "[Keras and NN Tutorial](https://indico.cern.ch/event/506145/contributions/2132944/attachments/1258124/1858154/NNinKeras_MPaganini.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free GPU usage: [Google Colaboratory notebooks](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) & [Kaggle Kernels](https://www.kaggle.com/kernels)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
